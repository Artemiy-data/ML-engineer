{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ee200f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import annoy\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "from string import punctuation\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import linear_model, metrics, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "59264cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(punctuation)\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "# Релизуем предобработку текста для классификатора\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"nan\", \"\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in exclude]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "# Релизуем предобработку текста для болталки и поиска товаров\n",
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57417ab5",
   "metadata": {},
   "source": [
    "#### Обучение классификатора «товарный запрос vs. болталка»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9fea38c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35548 entries, 0 to 35547\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   title           35548 non-null  object \n",
      " 1   descrirption    33537 non-null  object \n",
      " 2   product_id      35536 non-null  object \n",
      " 3   category_id     35536 non-null  float64\n",
      " 4   subcategory_id  35536 non-null  object \n",
      " 5   properties      35536 non-null  object \n",
      " 6   image_links     35533 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Загрузим датасет с продуктами\n",
    "data = pd.read_csv('ProductsDataset.csv')\n",
    "data.info()\n",
    "#Загрузим ответы из ранее обученной модели (болталки)\n",
    "index_map = pickle.load(open(\"index_map\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f9ef784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединим в один стобец название с описанием продукта и предобработаем\n",
    "data['text']= data['title'].apply(preprocess_text) + ' ' + data['descrirption'].apply(preprocess_text)\n",
    "# Целевая переменная для классификации\n",
    "data['target'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ed816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополним датасет данными из \"болталки\" и целевую переменную False \n",
    "talker = pd.DataFrame(list(index_map.items()),\n",
    "                   columns=['index', 'text'])\n",
    "talker = talker[talker.index < len(data)]\n",
    "talker['target'] = False\n",
    "talker = talker.drop(['index'], axis=1)\n",
    "talker['text'] = talker['text'].apply(preprocess_text)\n",
    "data_class = pd.concat([data, talker], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9f4196a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# делим выборку на обучающую и валидационную.\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(data_class['text'], data_class['target'])\n",
    "\n",
    "# labelEncode целевую переменную\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "db269ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Векторизируем текст при помощи TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer().fit(train_x.values)\n",
    "xtrain_tfidf = tfidf_vec.transform(train_x)\n",
    "xvalid_tfidf = tfidf_vec.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9ef177a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, WordLevel TF-IDF:  0.9794081242263981\n"
     ]
    }
   ],
   "source": [
    "# Обучим классификатор методом LogisticRegression на на Word Level TF IDF Vectors\n",
    "# Расчитаем метрику accuracy_score на валидации\n",
    "classifier = linear_model.LogisticRegression()\n",
    "classifier.fit(xtrain_tfidf, train_y)\n",
    "predictions = classifier.predict(xvalid_tfidf)\n",
    "accuracy = metrics.accuracy_score(predictions, valid_y)\n",
    "print(\"LR, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "57c196dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем модель классификатор\n",
    "# pickle.dump(classifier, open(\"text_classifier\",'wb'))\n",
    "# Загружаем модель классификатор\n",
    "classifier_model = pickle.load(open(\"text_classifier\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539b81f6",
   "metadata": {},
   "source": [
    "#### Реализуем поиск похожих товаров в контентной части бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "acb3839f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-95-fc723f8e14e7>:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for line in tqdm_notebook(data.text):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcdc77471874e81a61a9bcb850ed059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создадим список слов из названия и описания продуктов\n",
    "titles = []\n",
    "\n",
    "for line in tqdm_notebook(data.text):\n",
    "    spls = preprocess_txt(line)\n",
    "    titles.append(spls)\n",
    "\n",
    "# Векторизируем список слов при помощи модели Word2Vec и сохраним модель \n",
    "titles = [i for i in titles if len(i) > 2]\n",
    "product_model = Word2Vec(sentences=titles, vector_size=100, min_count=1, window=5)\n",
    "product_model.save(\"w2v_product_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "79791ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сложим в индексы все названия продуктов. Используем библиотеку annoy. \n",
    "# Проходимся по всем продуктам, считаем, что вектор продукта - усредненная сумма word2vecов слов.\n",
    "product_index = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "index_map_titles = {}\n",
    "counter = 0\n",
    "\n",
    "for quest in data.title:\n",
    "    n_w2v = 0\n",
    "    index_map_titles[counter] = str(data.product_id[counter]) + ' ' + data.title[counter]\n",
    "    question = preprocess_txt(quest)\n",
    "    vector = np.zeros(100)\n",
    "    for word in question:\n",
    "        if word in product_model.wv:\n",
    "            vector += product_model.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    product_index.add_item(counter, vector)\n",
    "        \n",
    "    counter += 1\n",
    "\n",
    "product_index.build(10)\n",
    "#product_index.save('titles.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e9faab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для поиска продуктов\n",
    "def find_product(question):\n",
    "    preprocessed_question = preprocess_txt(question)\n",
    "    n_w2v = 0\n",
    "    vector = np.zeros(100)\n",
    "    for word in preprocessed_question:\n",
    "        if word in product_model.wv:\n",
    "            vector += product_model.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    query_index = product_index.get_nns_by_vector(vector, 1)\n",
    "    return index_map_titles[query_index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df423c",
   "metadata": {},
   "source": [
    "#### Реализуем болталку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5e036874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для болталки возьмем обученную ранее модель и созданные индексы\n",
    "answer_model = Word2Vec.load(\"w2v_model\")\n",
    "answer_index = annoy.AnnoyIndex(100 ,'angular')\n",
    "answer_index.load('speaker.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d8cdcfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для ответов на запросы \"болталки\"\n",
    "def find_answer(question):\n",
    "    preprocessed_question = preprocess_txt(question)\n",
    "    n_w2v = 0\n",
    "    vector = np.zeros(100)\n",
    "    for word in preprocessed_question:\n",
    "        if word in answer_model.wv:\n",
    "            vector += answer_model.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    query_index = answer_index.get_nns_by_vector(vector, 1)\n",
    "    return index_map[query_index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fec20df",
   "metadata": {},
   "source": [
    "#### Напишем функцию и проверим работу нашего чат-бота-«барахольщика»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa2402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для ответа на запрос пользователя\n",
    "def get_answer(answer):\n",
    "    ans = pd.Series([answer], dtype=\"string\")\n",
    "    answer_tfidf = tfidf_vec.transform(ans) # Векторизируем запрос при помощи TfidfVectorizer\n",
    "    if classifier.predict(answer_tfidf)==1: # Если запрос был продуктовым, возвращаем id и название продукта\n",
    "        return find_product(answer)\n",
    "    else:\n",
    "        return find_answer(answer) # иначе отправляем запрос в болталку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f73a17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применим автотесты к методу get_answer\n",
    "assert(not get_answer(\"Где ключи от танка\").startswith(\"5\"))\n",
    "assert(get_answer(\"Юбка детская ORBY\").startswith(\"58e3cfe6132ca50e053f5f82\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "45856785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5bd6c8fb2138bbc55745362c Новая золотая ветровка'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим наглядно два возможных сценария: продуктовый запрос и нет\n",
    "get_answer('Новая золотая ветровка')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fac02657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 тонны. \\n'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer('Сколько весит слон?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
